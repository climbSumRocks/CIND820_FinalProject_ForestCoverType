---
title: "Final_Code"
author: "Haley Aldred"
date: "04/12/2021"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Introduction
This report contains my code for examining my data set, which will be used in classifying and predicting forest cover types in Roosevelt National Forest in Colorado, USA. My data comes from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/).

# Preparation Work
## Loading Libraries
```{r}
library(ggplot2)
library(tidyverse)
library(dplyr)
library(psych)
library(GGally)
library(scales)
library(texreg)
library(corrplot)
library(caret)
library(lattice)
library(e1071)
library(class)
library(randomForest)
```
# Data Exploration
Loading the data.
```{r}
data <- read.csv("~/School/CIND820/data/covtype.data.gz", header=FALSE, stringsAsFactors=TRUE)
#View(data)
```
Looking at the first few rows of data.
```{r}
head(data)
```
Adding column names based off the *covtype.info* document.
```{r}
colnames(data)<-c("elev", "aspect", "slope", "hHydro", "vHydro", "hRoad", "hs09", "hs12", "hs15", "hFire", "wild1", "wild2", "wild3", "wild4", "s1", "s2", "s3", "s4", "s5", "s6", "s7", "s8", "s9", "s10", "s11", "s12", "s13", "s14", "s15", "s16", "s17", "s18", "s19", "s20", "s21", "s22", "s23", "s24", "s25", "s26", "s27", "s28", "s29", "s30", "s31", "s32", "s33", "s34", "s35", "s36", "s37", "s38", "s39", "s40", "treeType")
```
Verifying the column names have been updated.
```{r}
head(data)
```
Looking at the last few rows of data.
```{r}
tail(data)
```
Verifying that there are no missing values.
```{r}
colSums(is.na(data))
```
Getting rid of binary wilderness area type and soil type columns. This will be done by concatenating the binary columns, converting them to numeric, and finding the log of the binary number.
```{r}
data$wildArea<-paste(data$wild1,data$wild2,data$wild3,data$wild4,sep="")
data$wildArea<-as.numeric(as.character(data$wildArea))
data$area<-(4-log(data$wildArea,10))
```
Next, we will do the same procedure for the 40 different soil types.
```{r}
data$soilType<-paste(data$s1,data$s2,data$s3,data$s4,data$s5,data$s6,data$s7,data$s8,data$s9,data$s10,data$s11,data$s12,data$s13,data$s14,data$s15,data$s16,data$s17,data$s18,data$s19,data$s20,data$s21,data$s22,data$s23,data$s24,data$s25,data$s26,data$s27,data$s28,data$s29,data$s30,data$s31,data$s32,data$s33,data$s34,data$s35,data$s36,data$s37,data$s38,data$s39,data$s40, sep="")
data$soilTypes<-as.numeric(as.character(data$soilType))
data$soil<-(40-log(data$soilTypes,10))
```
Next, we will calculated the euclidean distance to water.
```{r}
data$edHydro = (data$hHydro^2+data$vHydro^2)^.5


```
Now to delete the useless columns. By eliminating a combined 42 columns, it will make the data easier to work with in the future without losing any critical information.
```{r}
data<-select(data,-c(hHydro,vHydro,wild1,wild2,wild3,wild4,s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,s12,s13,s14,s15,s16,s17,s18,s19,s20,s21,s22,s23,s24,s25,s26,s27,s28,s29,s30,s31,s32,s33,s34,s35,s36,s37,s38,s39,s40,wildArea,soilType,soilTypes))
```
Verify the process worked.
```{r}
head(data)
tail(data)
```
Identifying tree types, adding a column for tree name
```{r}
data$treeName = 'a'
data$treeName[data$treeType==1] = 'Spruce-fir'
data$treeName[data$treeType==2] = 'Lodgepole Pine'
data$treeName[data$treeType==3] = 'Ponderosa Pine'
data$treeName[data$treeType==4] = 'Cottonwood-Willow'
data$treeName[data$treeType==5] = 'Aspen'
data$treeName[data$treeType==6] = 'Douglas-fir'
data$treeName[data$treeType==7] = 'Krummholz'
```
Identifying areas, adding a column for area name
```{r}
data$areaName = 'a'
data$areaName[data$area==1] = 'Rawah'
data$areaName[data$area==2] = 'Neota'
data$areaName[data$area==3] = 'Comanche Peak'
data$areaName[data$area==4] = 'Cache La Poudre'
```
Looking at the structure of the data. We will first create a dataset without the names.
```{r}
forest<-select(data,-c(treeName,areaName))
forest<-forest %>% relocate(treeType,.after=edHydro)

str(forest)
```
Looking at the basic data statistics.
```{r}
summary(forest)
```
The mean elevation of the area is 2959 m. The mean distance to water is 269.4 m. The mean distance to roads is 2350 m.The median tree type is number 2, also known as the lodgepole pine.
The median wilderness area is number 2, also know as Neota, and the median soil type is type 29, also know as Como which contains Legault families complex, extremely stony.


The psych package will be used to take a closer look at the data.
```{r}
describe(forest)
```
This indicates that there are 260796 instances for wilderness area 1 (Rawah), 29884 instances for wilderness area 2 (Neota), 253364 instances for wilderness area 3 (Comanche Peak), and 36968 instances for wilderness area 4 (Cache la Poudre).
The Rawah wilderness area has the most instances in the collected data, next is Comanche Peak.

Lets create a table of the different tree types.
```{r}
table(data$treeName)
```
This means there are 211840 instances of tree type 1 (spruce/fir), 283301 instances of tree type 2 (lodgepole pine), 35754 instances of tree type 3 (ponderosa pine), 2747 instances of tree type 4 (cottonwood/willow), 9493 instances of tree type 5 (aspen), 17367 instances of tree type 6 (douglas-fir), and 20510 instances of tree type 7 (krummholz). Tree type 2, or lodgepole pine, is the most frequent tree type found in the national forest. Cottonwood/willow trees are the most rare tree type in the forest.

We will do the same for the wilderness areas and soil types.
```{r}
table(data$areaName)
table(data$soil)
```
# Data Visualization
Let's look at the distribution of elevation for the data set.
```{r}
ggplot(data, aes(x=elev))+geom_histogram(breaks=seq(1500,4000,by=100),col="black",aes(fill=..count..))+scale_fill_gradient("Count",low="green",high="red")+labs(title="Histogram of Elevation",x="Elevation (m)",y="Count")
ggplot(data, aes(x=elev)) + geom_density()+labs(title="Density of Elevation",x="Elevation (m)",y="Density")
ggplot(data, aes(x=elev)) + geom_density(aes(group=treeName, colour=treeName, fill=treeName), alpha=0.3)+labs(title="Tree Density by Elevation",x="Elevation (m)",y="Density")

```
Let's look at the distribution of soil types for the data set.
```{r}
ggplot(data=data, aes(soil))+geom_histogram(breaks=seq(1,40,by=1),col="black",aes(fill=..count..))+scale_fill_gradient("Count",low="green",high="red")+labs(title="Histogram of Soil Types",x="Soil Type",y="Count")
ggplot(data,aes(areaName))+geom_density(aes(group=soil,colour=soil,fill=soil),alpha=0.3)+labs(main="Soils based on Wilderness Area",x="Wilderness Area",y="Density")
```
Let's look at the distribution of tree types for the data set.
```{r}
ggplot(data=data, aes(treeType))+geom_histogram(col="black",aes(fill=..count..))+scale_fill_gradient("Count",low="green",high="red")+labs(title="Histogram of Tree Types",x="Tree Type Type",y="Count")
ggplot(data, aes(x=areaName)) + geom_density(aes(group=treeName, colour=treeName, fill=treeName), alpha=0.3)+labs(main="Tree Density by Area",x="Area Name",y="Density")
```
Next, we will create a correlation matrix of the data.
```{r}
corForest<-cor(forest)
head(corForest)
```
Now we will create a correlogram to visualize the correlation matrix.
```{r}
pairs(corForest)
corrplot.mixed(corForest,lower.col="black",number.cex=0.75)
```
Negative slopes show a negative correlation, while positive slopes show a positive correlation between two attributes. Attributes with the highest correlation to tree type include area. 

# Data Analysis
We will split the data into testing and training samples for our detailed analysis. Due to RAM constraints, we will use a small subsection of the large data set.
```{r}
set.seed(42)
index1<- sample((1/100)*nrow(data), replace = FALSE)
data<- data[index1,]
forestN<-select(data,-c(treeName,areaName))
sample_size=round(nrow(forestN)*.70)
index<-sample(seq_len(nrow(forestN)),size=sample_size)
train<-forestN[index, ]
test<-forestN[-index, ]
```
## K-Nearest Neighbour Classification
The K-nearest neighbour algorithm will be used to predict the tree type based on other variables.
```{r}
k.predict<-knn(train = train[,1:12], test = test[,1:12], cl = as.factor(train$treeType), k = 3)
plot(k.predict)
```
The value for k (number of neighbours) was chosen by running the prediction model with different k values each time. Three was chosen as the best k value because it had the highest accuracy out of all the values tested.

Now let's look at the confusion matrix to determine the accuracy and efficiency of the model.
```{r}
confMatrixK<-table(k.predict,test$treeType)
confusionMatrix(confMatrixK)
```
The accuracy of the model is 81%.

## Random Forest Classification
Now we will look at the Random Forest Classifier.
```{r}
classifier=randomForest(factor(train$treeType)~.,data=train)
plot(classifier,main="Random Forest Classification")
```
Now we will use the classifier to predict tree type.
```{r}
rf.predict<-predict(classifier,test)
varImpPlot(classifier,main="Variable Importance")
```
The Variable importance plot shows the mean decrease in node impurity. Therefore elevation is an important indicator of tree type.

Looking at the confusion matrix.
```{r}
confMatrixTree<-table(rf.predict,test$treeType)
confusionMatrix(confMatrixTree)
```
The accuracy of the Random Forest model is 84%.
```
